{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.colors import to_rgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHS_OUTPUT_DIR = './SRDS-graphs-pngs'\n",
    "graph_png_save_dir = GRAPHS_OUTPUT_DIR\n",
    "# make dir if it doesn't exist already\n",
    "if not os.path.exists(f\"{GRAPHS_OUTPUT_DIR}/\"):\n",
    "    os.makedirs(f\"{GRAPHS_OUTPUT_DIR}/\")\n",
    "# delete existing files in the directory, if any:\n",
    "existing_files = os.listdir(f'{GRAPHS_OUTPUT_DIR}/')\n",
    "for f in existing_files:\n",
    "    os.remove(f\"{GRAPHS_OUTPUT_DIR}/{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv files into memory\n",
    "csv_dir = './SRDS-results/'\n",
    "csv_filenames = os.listdir(csv_dir)\n",
    "csv_filenames[:] = [x for x in csv_filenames if x != '.DS_Store'] # remove '.DS_Store' if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort csv files figures-wise\n",
    "figs_list = ['7a', '7b', '7c', '7d', '8a', '8b', '8c', '8d', '9a', '9b', '10a', '10b', '11a', '11b', '11c', '13a', '13b', 'A1a', 'A1b']\n",
    "fig_wise_csvs = {}\n",
    "for fig_no in figs_list:\n",
    "    fig_wise_csvs[fig_no] = []\n",
    "    for file in csv_filenames:\n",
    "        if file.split('_')[0] == fig_no:\n",
    "            fig_wise_csvs[fig_no].append(file)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up structures to hold dataframes\n",
    "all_dfs = {}\n",
    "\n",
    "two_dfs_figs = ['10a', '10b', '11a', '11b']\n",
    "\n",
    "df_template = pd.DataFrame(\n",
    "    {\n",
    "        'sites': [],\n",
    "        'configuration': [],\n",
    "        'reconfiguration': [],\n",
    "        'hurricane': [],\n",
    "        'method': [],\n",
    "        'bucket': [],\n",
    "        'green': [],\n",
    "        'orange': [],\n",
    "        'red': [],\n",
    "        'yellow': [],\n",
    "        'blue': [],\n",
    "        'gray': [],\n",
    "    }\n",
    ")\n",
    "\n",
    "for fig in figs_list:\n",
    "    all_dfs[fig] = []\n",
    "    df_tmp = df_template.copy()\n",
    "    all_dfs[fig].append(df_tmp)\n",
    "    if fig in two_dfs_figs:\n",
    "        df_tmp2 = df_template.copy()\n",
    "        all_dfs[fig].append(df_tmp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frames from the csv files and save into all_dfs dict\n",
    "for fig in fig_wise_csvs:\n",
    "    for csv_file in fig_wise_csvs[fig]:\n",
    "        file_content = pd.read_csv(f\"./{csv_dir}/{csv_file}\")\n",
    "    \n",
    "        prob_g = file_content['green_probability'][0]\n",
    "        prob_o = file_content['orange_probability'][0]\n",
    "        prob_r = file_content['red_probability'][0]\n",
    "        prob_y = file_content['yellow_probability'][0]\n",
    "        prob_b = file_content['blue_probability'][0]\n",
    "        prob_x = file_content['grey_probability'][0]\n",
    "\n",
    "        method = file_content['method'][0]\n",
    "        bucket = file_content['bucket'][0]\n",
    "\n",
    "        config = (csv_file.split('_')[1]).split('.')[0]\n",
    "        if config == '1r6+6+6':\n",
    "            config = '6+6+6'\n",
    "            rec = 'H->R->CA'\n",
    "        elif config == '2r6+6+6':\n",
    "            config = '6+6+6'\n",
    "            rec = 'H->CA->R'\n",
    "        else:\n",
    "            rec = 'No'\n",
    "        \n",
    "        if fig not in two_dfs_figs:\n",
    "            idx = 0\n",
    "        else:\n",
    "            tmp = (csv_file.split('_')[2]).split('.')[0]\n",
    "            if tmp in ['W', 'J']:\n",
    "                idx = 0\n",
    "            elif tmp in ['K', 'M']:\n",
    "                idx = 1\n",
    "        \n",
    "        # sites = static_data[fig]['sites']\n",
    "        # hurr = static_data[fig]['hurr']\n",
    "        sites = ''\n",
    "        hurr = ''\n",
    "\n",
    "        df_row = [sites, config, rec, hurr, method, bucket, prob_g, prob_o, prob_r, prob_y, prob_b, prob_x]\n",
    "        this_df = all_dfs[fig][idx]\n",
    "        this_df.loc[-1] = df_row\n",
    "        this_df.index = this_df.index + 1\n",
    "        this_df = this_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pngs_override = False # if this is true then wont save pngs in all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_graph(df_original, vs_graphs=False, auto_title=True, title='', add_hatches=False, save_graph_name=None, verticle_lines=2, fig_w=None, fig_h=None, relative_width_bar=None, override_x_labels=None, overlapping_labels_case=False):\n",
    "    df = df_original.copy()\n",
    "    \n",
    "    # graph specifications:\n",
    "    _color_list = [\"mediumseagreen\", \"orange\", \"red\", \"yellow\", \"blue\", \"lightslategrey\"]\n",
    "    color_list = [to_rgb(i) for i in _color_list]\n",
    "    # patterns = [ \"/\" , \"\\\\\" , \"|\" , \"-\" , \"+\" , \"x\", \"o\", \"O\", \".\", \"*\" ]\n",
    "    patterns = {\n",
    "        to_rgb(\"mediumseagreen\"): \".\", \n",
    "        to_rgb(\"orange\"): \"\\\\\", \n",
    "        to_rgb(\"red\"): \"/\", \n",
    "        to_rgb(\"yellow\"): \"-\", \n",
    "        to_rgb(\"blue\"): \"+\", \n",
    "        to_rgb(\"lightslategrey\"): \"x\",\n",
    "    }\n",
    "    patterns_color = None if not add_hatches else 'silver'\n",
    "    rc_param_xtick = 18\n",
    "    rc_param_ytick = 18\n",
    "    rc_param_font_size = 18\n",
    "    x_tick_font_size = 30\n",
    "    y_tick_font_size = 34\n",
    "    y_axis_label_font_size = 34\n",
    "    bars_value_font_size = 34\n",
    "    vertical_dividers_font_size = 18\n",
    "    fig_size_w = 15 if fig_w is None else fig_w\n",
    "    fig_size_h = 10 if fig_h is None else fig_h\n",
    "    bar_width = 0.8 if relative_width_bar is None else relative_width_bar # width of bar relative to space it is alloted. e.g 0.8 would add some space between the bar and the next one. 1 would leave no space between bars.\n",
    "    # pd.set_option('expand_frame_repr', False)\n",
    "    plt.rc('xtick', labelsize=rc_param_xtick) \n",
    "    plt.rc('ytick', labelsize=rc_param_ytick)\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    plt.rcParams[\"font.size\"] = str(rc_param_font_size)\n",
    "\n",
    "    # x-axis adjustment:\n",
    "    if not vs_graphs:\n",
    "        df.loc[df[\"reconfiguration\"].str.endswith('H->R->CA'), \"configuration\"] = \"rec. 6+6+6\\n(H→R→CA)\"\n",
    "        df.loc[df[\"reconfiguration\"].str.endswith('H->CA->R'), \"configuration\"] = \"rec. 6+6+6\\n(H→CA→R)\"\n",
    "        df['configuration'] = pd.Categorical(df['configuration'], [\"2\", \"2+2\", \"6\",\"6+6\", \"6+6+6\", \"rec. 6+6+6\\n(H→CA→R)\", \"rec. 6+6+6\\n(H→R→CA)\"]) # sort order\n",
    "        df = df.sort_values(\"configuration\")\n",
    "    df['configuration'] = df['configuration'].replace(['2+2'], '2-2') # internally 2+2 is used to represent 2-2 in the tool\n",
    "    df['configuration'] = df['configuration'].replace(['6+6'], '6-6') # internally 6+6 is used to represent 6-6 in the tool\n",
    "\n",
    "    # graph title/subtitle\n",
    "    if auto_title:\n",
    "        graph_title = ''\n",
    "        graph_title += 'hurricane=' + df['hurricane'][0] + '; '\n",
    "        graph_title += 'sites=' + df['sites'][0] + '; '\n",
    "        graph_title += 'method=' + df['method'][0] + '; '\n",
    "        graph_title += 'bucket=' + df['bucket'][0] + '; '\n",
    "    else:\n",
    "        graph_title = title\n",
    "\n",
    "    # generate graph object (+ temporarily drop every column except colors as they are not directly being used for column values):\n",
    "    # print(graph_title)\n",
    "    graph = df.drop(['sites', 'reconfiguration', 'hurricane', 'method', 'bucket'], inplace=False, axis=1).plot.bar(x='configuration', stacked=True, title=graph_title, color=color_list, legend=False, figsize=(fig_size_w, fig_size_h), width=bar_width, rot=0, edgecolor=patterns_color) # rot = degree of rotation for x labels\n",
    "    \n",
    "    bar_num = 0 if vs_graphs else None\n",
    "    total_verticle_lines = verticle_lines\n",
    "    extra_verticle_buffer = -0.02 if not overlapping_labels_case else -0.055\n",
    "    for bar in graph.patches:\n",
    "        if add_hatches:\n",
    "            bar.set_hatch(patterns[(bar.get_facecolor()[0], bar.get_facecolor()[1], bar.get_facecolor()[2])])\n",
    "        # This is actual value we'll show.\n",
    "        value = f'{str(np.round(bar.get_height()*100, 2))}%'\n",
    "        if(bar.get_height()>0.0):\n",
    "            graph.annotate(\n",
    "                value,\n",
    "                # Put the text in the middle of each bar. get_x +half_width, get_y + half_height.\n",
    "                (bar.get_x()+bar.get_width()/2,(bar.get_y()+np.round(bar.get_height(),decimals=4)/2)+extra_verticle_buffer),\n",
    "                size=bars_value_font_size,\n",
    "                ha='center',\n",
    "                weight='bold'\n",
    "            )\n",
    "            extra_verticle_buffer = extra_verticle_buffer + 0.005 if overlapping_labels_case else -0.02\n",
    "        if vs_graphs and bar_num <= total_verticle_lines+1:\n",
    "            bar_num += 1\n",
    "            if (bar_num % 2) == 0: # after even numbered bar, add a verticle line\n",
    "                y = 0.0\n",
    "                while y < 1:\n",
    "                    graph.annotate(\n",
    "                        '|', \n",
    "                        xy=(bar_num - 0.525, y),\n",
    "                        fontweight='bold',\n",
    "                        fontsize=vertical_dividers_font_size,\n",
    "                        )\n",
    "                    y += 0.1\n",
    "\n",
    "    # adjust minor issues with x and y ticks\n",
    "    # the following would apply newline character to x ticks if any\n",
    "    if override_x_labels is None:\n",
    "        x_tick_labels = graph.get_xticklabels()\n",
    "    else:\n",
    "        x_tick_labels = override_x_labels\n",
    "    plt.xticks(range(len(x_tick_labels)), x_tick_labels, fontsize=x_tick_font_size)\n",
    "    # convert y ticks to percentage values:\n",
    "    # y_tick_labels = graph.get_yticklabels()\n",
    "    # y_tick_labels = ['0%', '20%', '40%', '60%', '80%', '100%']\n",
    "    # plt.yticks(range(len(y_tick_labels)), y_tick_labels)\n",
    "    graph.yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "    plt.yticks(fontsize=y_tick_font_size)\n",
    "\n",
    "    # x and y axis labels\n",
    "    # plt.xlabel(\"System Configuration\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Probability of Operational State\", fontsize=y_axis_label_font_size)\n",
    "    \n",
    "    if save_graph_name is not None:\n",
    "        if save_pngs_override == False:\n",
    "            plt.savefig(f\"{graph_png_save_dir}/{save_graph_name}.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_standard_graph(df_key, exclude=None, auto_title=False, title='', save_graph_name=None, verticle_lines=2, fig_w=None, fig_h=None, relative_width_bar=None, override_x_labels=None, overlapping_labels_case=False):\n",
    "    # standard graph as in for one specific sites-config (e.g. Honolulu+Waiau+DRFortress) with the possible system configs (2-2, 6-6 etc) for the given method and bucket in the df_key. excludes configs in the param exclude\n",
    "\n",
    "    df = all_dfs[df_key][0].copy()\n",
    "    if exclude is not None:\n",
    "        for c in exclude:\n",
    "            if c in ['H->CA->R', 'H->R->CA']:\n",
    "                df.drop(df.loc[df['reconfiguration'].str.fullmatch(c)].index, inplace=True)\n",
    "            elif c in ['2+2', '6+6+6']:\n",
    "                df.drop(df.loc[df['configuration'].str.endswith(c)].index, inplace=True)\n",
    "            else:\n",
    "                df.drop(df.loc[df['configuration'].str.fullmatch(c)].index, inplace=True)\n",
    "        df.reset_index(inplace = True)\n",
    "        df.drop(['index'], inplace=True, axis=1)\n",
    "\n",
    "    _make_graph(df, auto_title=auto_title, title=title, save_graph_name=save_graph_name, verticle_lines=verticle_lines, fig_w=fig_w, fig_h=fig_h, relative_width_bar=relative_width_bar, override_x_labels=override_x_labels, overlapping_labels_case=overlapping_labels_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vs_graph(key_a, key_b, comparison_side_a, comparison_side_b, exclude=None, auto_title=False, title='', save_graph_name=None, verticle_lines=2):\n",
    "    dfa =  all_dfs[key_a][0].copy()\n",
    "    dfb =  all_dfs[key_b][1].copy()\n",
    "\n",
    "    cols_renamed = {}\n",
    "    if exclude is not None:\n",
    "        for c in exclude:\n",
    "            if c in ['H->CA->R', 'H->R->CA']:\n",
    "                dfa.drop(dfa.loc[dfa['reconfiguration'].str.fullmatch(c)].index, inplace=True)\n",
    "                dfb.drop(dfb.loc[dfb['reconfiguration'].str.fullmatch(c)].index, inplace=True)\n",
    "            elif c in ['6+6']:\n",
    "                dfa.drop(dfa.loc[(dfa['configuration'].str.fullmatch('6+6') & dfa['reconfiguration'].str.fullmatch('No'))].index, inplace=True)\n",
    "                dfb.drop(dfb.loc[(dfb['configuration'].str.fullmatch('6+6') & dfb['reconfiguration'].str.fullmatch('No'))].index, inplace=True)\n",
    "            elif c in ['2+2']:\n",
    "                dfa.drop(dfa.loc[dfa['configuration'].str.endswith('+2')].index, inplace=True)\n",
    "                dfb.drop(dfb.loc[dfb['configuration'].str.endswith('+2')].index, inplace=True)\n",
    "            elif c in ['6+6+6']:\n",
    "                dfa.drop(dfa.loc[(dfa['configuration'].str.fullmatch('6+6+6') & dfa['reconfiguration'].str.fullmatch('No'))].index, inplace=True)\n",
    "                dfb.drop(dfb.loc[(dfb['configuration'].str.fullmatch('6+6+6') & dfb['reconfiguration'].str.fullmatch('No'))].index, inplace=True)\n",
    "            else:\n",
    "                dfa.drop(dfa.loc[dfa['configuration'].str.fullmatch(c)].index, inplace=True)\n",
    "                dfb.drop(dfb.loc[dfb['configuration'].str.fullmatch(c)].index, inplace=True)\n",
    "\n",
    "    if exclude is not None:\n",
    "        if '2+2' not in exclude:\n",
    "            dfa.loc[dfa[\"configuration\"].str.endswith('2+2'), \"configuration\"] = f\"2-2\\n{comparison_side_a}\"\n",
    "            dfb.loc[dfb[\"configuration\"].str.endswith('2+2'), \"configuration\"] = f\"2-2\\n{comparison_side_b}\"\n",
    "            cols_renamed['2+2'] = [f\"2-2\\n{comparison_side_a}\", f\"2-2\\n{comparison_side_b}\"]\n",
    "        if '6+6+6' not in exclude:\n",
    "            dfa.loc[dfa[\"configuration\"].str.endswith('6+6+6'), \"configuration\"] = f\"6+6+6\\n{comparison_side_a}\"\n",
    "            dfb.loc[dfb[\"configuration\"].str.endswith('6+6+6'), \"configuration\"] = f\"6+6+6\\n{comparison_side_b}\"\n",
    "            cols_renamed['6+6+6'] = [f\"6+6+6\\n{comparison_side_a}\", f\"6+6+6\\n{comparison_side_b}\"]\n",
    "        if '6+6' not in exclude:\n",
    "            dfa.loc[dfa[\"configuration\"].str.endswith('6+6'), \"configuration\"] = f\"6-6\\n{comparison_side_a}\"\n",
    "            dfb.loc[dfb[\"configuration\"].str.endswith('6+6'), \"configuration\"] = f\"6-6\\n{comparison_side_b}\"\n",
    "            cols_renamed['6+6'] = [f\"6-6\\n{comparison_side_a}\", f\"6-6\\n{comparison_side_b}\"]\n",
    "\n",
    "    vs_df = pd.concat([dfa, dfb])\n",
    "\n",
    "    vs_df['configuration'] = pd.Categorical(vs_df['configuration'], [f\"2-2\\n{comparison_side_a}\", f\"2-2\\n{comparison_side_b}\", f\"6-6\\n{comparison_side_a}\", f\"6-6\\n{comparison_side_b}\", f\"6+6+6\\n{comparison_side_a}\", f\"6+6+6\\n{comparison_side_b}\"]) # sort order\n",
    "    vs_df = vs_df.sort_values(\"configuration\")\n",
    "    vs_df.reset_index(inplace = True)\n",
    "    vs_df.drop(['index'], inplace=True, axis=1)\n",
    "\n",
    "    _make_graph(vs_df, vs_graphs=True, auto_title=auto_title, title=title, save_graph_name=save_graph_name, verticle_lines=verticle_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 7a:\n",
    "key = '7a'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig7a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 7b:\n",
    "key = '7b'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 7c:\n",
    "key = '7c'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig7c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 7d:\n",
    "key = '7d'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig7d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 8a:\n",
    "key = '8a'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig8a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 8b:\n",
    "key = '8b'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig8b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 8c:\n",
    "key = '8c'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig8c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 8d:\n",
    "key = '8d'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig8d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 9a:\n",
    "key = '9a'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig9a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 9b:\n",
    "key = '9b'\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig9b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 10a:\n",
    "key_a = key_b = '10a'\n",
    "\n",
    "comp_str_a = 'Waiau'\n",
    "comp_str_b = 'Kahe'\n",
    "\n",
    "# exclude_configs = ['2', '6', 'H->CA->R', 'H->R->CA']\n",
    "exclude_configs = ['2', '6', 'H->CA->R', 'H->R->CA', '2+2']\n",
    "\n",
    "make_vs_graph(key_a, key_b, comp_str_a, comp_str_b, exclude=exclude_configs, save_graph_name='fig10a', verticle_lines=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 10b: \n",
    "key_a = key_b = '10b'\n",
    "\n",
    "comp_str_a = 'Waiau'\n",
    "comp_str_b = 'Kahe'\n",
    "\n",
    "# exclude_configs = ['2', '6', 'H->CA->R', 'H->R->CA']\n",
    "exclude_configs = ['2', '6', 'H->CA->R', 'H->R->CA', '2+2']\n",
    "\n",
    "make_vs_graph(key_a, key_b, comp_str_a, comp_str_b, exclude=exclude_configs, save_graph_name='fig10b', verticle_lines=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 11a:\n",
    "key_a = key_b = '11a'\n",
    "\n",
    "comp_str_a = 'Jacksonville'\n",
    "comp_str_b = 'Miami'\n",
    "\n",
    "# ======\n",
    "\n",
    "dfa =  all_dfs[key_a][0].copy()\n",
    "dfb =  all_dfs[key_b][1].copy()\n",
    "\n",
    "# not using these\n",
    "dfa.drop(dfa.loc[dfa['reconfiguration'].str.fullmatch('H->CA->R')].index, inplace=True)\n",
    "dfb.drop(dfb.loc[dfb['reconfiguration'].str.fullmatch('H->CA->R')].index, inplace=True)\n",
    "dfa.drop(dfa.loc[dfa['reconfiguration'].str.fullmatch('H->R->CA')].index, inplace=True)\n",
    "dfb.drop(dfb.loc[dfb['reconfiguration'].str.fullmatch('H->R->CA')].index, inplace=True)\n",
    "dfa.drop(dfa.loc[dfa['configuration'].str.fullmatch('2')].index, inplace=True)\n",
    "dfb.drop(dfb.loc[dfb['configuration'].str.fullmatch('2')].index, inplace=True)\n",
    "dfa.drop(dfa.loc[dfa['configuration'].str.fullmatch('6')].index, inplace=True)\n",
    "dfb.drop(dfb.loc[dfb['configuration'].str.fullmatch('6')].index, inplace=True)\n",
    "\n",
    "# rename cols. mark to remove 2-2 and 6-6 for one side as they are the same and rename the remaining one column with both names\n",
    "dfa.loc[dfa[\"configuration\"].str.endswith('2+2'), \"configuration\"] = f\"2-2\"\n",
    "dfb.drop(dfb.loc[dfb['configuration'].str.endswith('2+2')].index, inplace=True)\n",
    "# dfb.loc[dfb[\"configuration\"].str.endswith('2+2'), \"configuration\"] = \"remove\"\n",
    "dfa.loc[dfa[\"configuration\"].str.endswith('6+6+6'), \"configuration\"] = f\"6+6+6\\n{comp_str_a}\"\n",
    "dfb.loc[dfb[\"configuration\"].str.endswith('6+6+6'), \"configuration\"] = f\"6+6+6\\n{comp_str_b}\"\n",
    "dfa.loc[dfa[\"configuration\"].str.endswith('6+6'), \"configuration\"] = f\"6-6\"\n",
    "dfb.drop(dfb.loc[dfb['configuration'].str.endswith('6+6')].index, inplace=True)\n",
    "# dfb.loc[dfb[\"configuration\"].str.endswith('6+6'), \"configuration\"] = \"remove\"\n",
    "\n",
    "\n",
    "vs_df = pd.concat([dfa, dfb])\n",
    "\n",
    "# remove marked cols \n",
    "# vs_df.drop(vs_df.loc[vs_df['configuration'].str.endswith(\"remove\")].index, inplace=True)\n",
    "# vs_df.drop(vs_df.loc[vs_df['configuration'].str.fullmatch(\"2-2(remove)\")].index, inplace=True)\n",
    "\n",
    "vs_df['configuration'] = pd.Categorical(vs_df['configuration'], [\"2-2\", \"6-6\", f\"6+6+6\\n{comp_str_a}\", f\"6+6+6\\n{comp_str_b}\"]) # sort order\n",
    "vs_df = vs_df.sort_values(\"configuration\")\n",
    "vs_df.reset_index(inplace = True)\n",
    "vs_df.drop(['index'], inplace=True, axis=1)\n",
    "\n",
    "_make_graph(vs_df, vs_graphs=True, auto_title=False, title='', verticle_lines=0, save_graph_name='fig11a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 11b\n",
    "key_a = key_b = '11b'\n",
    "\n",
    "comp_str_a = 'Jacksonville'\n",
    "comp_str_b = 'Miami'\n",
    "\n",
    "# ======\n",
    "\n",
    "dfa =  all_dfs[key_a][0].copy()\n",
    "dfb =  all_dfs[key_b][1].copy()\n",
    "\n",
    "# not using these\n",
    "dfa.drop(dfa.loc[dfa['reconfiguration'].str.fullmatch('H->CA->R')].index, inplace=True)\n",
    "dfb.drop(dfb.loc[dfb['reconfiguration'].str.fullmatch('H->CA->R')].index, inplace=True)\n",
    "dfa.drop(dfa.loc[dfa['reconfiguration'].str.fullmatch('H->R->CA')].index, inplace=True)\n",
    "dfb.drop(dfb.loc[dfb['reconfiguration'].str.fullmatch('H->R->CA')].index, inplace=True)\n",
    "dfa.drop(dfa.loc[dfa['configuration'].str.fullmatch('2')].index, inplace=True)\n",
    "dfb.drop(dfb.loc[dfb['configuration'].str.fullmatch('2')].index, inplace=True)\n",
    "dfa.drop(dfa.loc[dfa['configuration'].str.fullmatch('6')].index, inplace=True)\n",
    "dfb.drop(dfb.loc[dfb['configuration'].str.fullmatch('6')].index, inplace=True)\n",
    "\n",
    "# rename cols. mark to remove 2-2 and 6-6 for one side as they are the same and rename the remaining one column with both names\n",
    "dfa.loc[dfa[\"configuration\"].str.endswith('2+2'), \"configuration\"] = \"2-2\"\n",
    "dfb.drop(dfb.loc[dfb['configuration'].str.endswith('2+2')].index, inplace=True)\n",
    "# dfb.loc[dfb[\"configuration\"].str.endswith('2+2'), \"configuration\"] = \"remove\"\n",
    "dfa.loc[dfa[\"configuration\"].str.endswith('6+6+6'), \"configuration\"] = f\"6+6+6\\n{comp_str_a}\"\n",
    "dfb.loc[dfb[\"configuration\"].str.endswith('6+6+6'), \"configuration\"] = f\"6+6+6\\n{comp_str_b}\"\n",
    "dfa.loc[dfa[\"configuration\"].str.endswith('6+6'), \"configuration\"] = \"6-6\"\n",
    "dfb.drop(dfb.loc[dfb['configuration'].str.endswith('6+6')].index, inplace=True)\n",
    "# dfb.loc[dfb[\"configuration\"].str.endswith('6+6'), \"configuration\"] = \"remove\"\n",
    "\n",
    "\n",
    "vs_df = pd.concat([dfa, dfb])\n",
    "\n",
    "# remove marked cols \n",
    "# vs_df.drop(vs_df.loc[vs_df['configuration'].str.endswith(\"remove\")].index, inplace=True)\n",
    "# vs_df.drop(vs_df.loc[vs_df['configuration'].str.fullmatch(\"2-2(remove)\")].index, inplace=True)\n",
    "\n",
    "vs_df['configuration'] = pd.Categorical(vs_df['configuration'], [\"2-2\", \"6-6\", f\"6+6+6\\n{comp_str_a}\", f\"6+6+6\\n{comp_str_b}\"]) # sort order\n",
    "vs_df = vs_df.sort_values(\"configuration\")\n",
    "vs_df.reset_index(inplace = True)\n",
    "vs_df.drop(['index'], inplace=True, axis=1)\n",
    "\n",
    "_make_graph(vs_df, vs_graphs=True, auto_title=False, title='', verticle_lines=0, save_graph_name='fig11b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 11c\n",
    "\n",
    "key = '11c'\n",
    "# exclude_configs = ['H->CA->R', '2', '2+2', '6+6+6', '6']\n",
    "# make_standard_graph(key, exclude=exclude_configs)\n",
    "\n",
    "df = all_dfs[key][0].copy()\n",
    "\n",
    "df.drop(df.loc[df['reconfiguration'].str.fullmatch('H->CA->R')].index, inplace=True)\n",
    "df.drop(df.loc[df['configuration'].str.fullmatch('2')].index, inplace=True)\n",
    "df.drop(df.loc[df['configuration'].str.fullmatch('6')].index, inplace=True)\n",
    "df.drop(df.loc[df['configuration'].str.endswith('2+2')].index, inplace=True)\n",
    "df.drop(df.loc[(df['configuration'].str.endswith('6+6+6') & df['reconfiguration'].str.fullmatch('No'))].index, inplace=True)\n",
    "df.drop(df.loc[(df['configuration'].str.endswith('6+6') & df['reconfiguration'].str.fullmatch('No'))].index, inplace=True)\n",
    "\n",
    "_make_graph(df, auto_title=False, title='', relative_width_bar=0.5, fig_w=5, override_x_labels=['rec. 6+6+6\\nMiami'], save_graph_name='fig11c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 13a:\n",
    "key = '13a'\n",
    "exclude_configs = ['2', '2+2', '6']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig13a', overlapping_labels_case=True, override_x_labels=['6-6', '6+6+6', 'rec. 6+6+6', 'rec. 6+6+6\\n(preemptive)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 13b:\n",
    "key = '13b'\n",
    "exclude_configs = ['2', '2+2', '6']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='fig13b', override_x_labels=['6-6', '6+6+6', 'rec. 6+6+6', 'rec. 6+6+6\\n(preemptive)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig A1a\n",
    "\n",
    "key = 'A1a'\n",
    "\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='figA1a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig A1b:\n",
    "\n",
    "key = 'A1b'\n",
    "\n",
    "exclude_configs = ['H->CA->R', 'H->R->CA']\n",
    "make_standard_graph(key, exclude=exclude_configs, save_graph_name='figA1b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scada_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
